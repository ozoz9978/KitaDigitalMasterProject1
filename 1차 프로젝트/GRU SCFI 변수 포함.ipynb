{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e245ccfb-ca1e-4fc2-bd31-357493194bd9",
   "metadata": {
    "id": "e245ccfb-ca1e-4fc2-bd31-357493194bd9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dense, Dropout, Input\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "230675c4-c907-45a4-8159-46a8f229432c",
   "metadata": {
    "id": "230675c4-c907-45a4-8159-46a8f229432c"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"화이팅_ㅋ.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "370f2428-1bb0-4c89-91c1-6bc0a8df8c4c",
   "metadata": {
    "id": "370f2428-1bb0-4c89-91c1-6bc0a8df8c4c",
    "outputId": "d55b7550-3c32-45e6-8417-ab81c0fd4cb3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>주차</th>\n",
       "      <th>SCFI</th>\n",
       "      <th>코로나확진자</th>\n",
       "      <th>환율</th>\n",
       "      <th>WTI유가</th>\n",
       "      <th>나프타유가</th>\n",
       "      <th>고유황중유가</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-1</td>\n",
       "      <td>1148.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1056.49</td>\n",
       "      <td>93.56</td>\n",
       "      <td>106.6980</td>\n",
       "      <td>96.1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-2</td>\n",
       "      <td>1232.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1058.35</td>\n",
       "      <td>95.56</td>\n",
       "      <td>105.0360</td>\n",
       "      <td>97.7760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-3</td>\n",
       "      <td>1245.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1075.58</td>\n",
       "      <td>95.88</td>\n",
       "      <td>103.4800</td>\n",
       "      <td>97.2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-4</td>\n",
       "      <td>1227.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1095.19</td>\n",
       "      <td>97.77</td>\n",
       "      <td>106.6620</td>\n",
       "      <td>97.4920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-5</td>\n",
       "      <td>1219.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1096.00</td>\n",
       "      <td>95.72</td>\n",
       "      <td>108.1780</td>\n",
       "      <td>98.5660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>2024-15</td>\n",
       "      <td>1757.04</td>\n",
       "      <td>39459.0</td>\n",
       "      <td>1374.30</td>\n",
       "      <td>83.14</td>\n",
       "      <td>74.9875</td>\n",
       "      <td>79.6475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>2024-16</td>\n",
       "      <td>1769.54</td>\n",
       "      <td>31841.0</td>\n",
       "      <td>1376.43</td>\n",
       "      <td>83.85</td>\n",
       "      <td>74.3400</td>\n",
       "      <td>80.8120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>2024-17</td>\n",
       "      <td>1940.63</td>\n",
       "      <td>34278.0</td>\n",
       "      <td>1354.63</td>\n",
       "      <td>78.11</td>\n",
       "      <td>75.0220</td>\n",
       "      <td>80.4920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>2024-19</td>\n",
       "      <td>2305.79</td>\n",
       "      <td>33678.0</td>\n",
       "      <td>1351.76</td>\n",
       "      <td>80.06</td>\n",
       "      <td>71.8160</td>\n",
       "      <td>81.2640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>2024-20</td>\n",
       "      <td>2520.76</td>\n",
       "      <td>36014.0</td>\n",
       "      <td>1365.93</td>\n",
       "      <td>77.72</td>\n",
       "      <td>70.4220</td>\n",
       "      <td>79.8220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>589 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          주차     SCFI   코로나확진자       환율  WTI유가     나프타유가   고유황중유가\n",
       "0     2013-1  1148.08      0.0  1056.49  93.56  106.6980  96.1060\n",
       "1     2013-2  1232.35      0.0  1058.35  95.56  105.0360  97.7760\n",
       "2     2013-3  1245.84      0.0  1075.58  95.88  103.4800  97.2140\n",
       "3     2013-4  1227.84      0.0  1095.19  97.77  106.6620  97.4920\n",
       "4     2013-5  1219.39      0.0  1096.00  95.72  108.1780  98.5660\n",
       "..       ...      ...      ...      ...    ...       ...      ...\n",
       "584  2024-15  1757.04  39459.0  1374.30  83.14   74.9875  79.6475\n",
       "585  2024-16  1769.54  31841.0  1376.43  83.85   74.3400  80.8120\n",
       "586  2024-17  1940.63  34278.0  1354.63  78.11   75.0220  80.4920\n",
       "587  2024-19  2305.79  33678.0  1351.76  80.06   71.8160  81.2640\n",
       "588  2024-20  2520.76  36014.0  1365.93  77.72   70.4220  79.8220\n",
       "\n",
       "[589 rows x 7 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aae30de8-b868-4c1c-9082-ebf3a7f21363",
   "metadata": {
    "id": "aae30de8-b868-4c1c-9082-ebf3a7f21363"
   },
   "outputs": [],
   "source": [
    "# 날짜를 인덱스로 설정\n",
    "df.set_index('주차', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a4efad0b-d928-43fe-8690-ae970e70eb50",
   "metadata": {
    "id": "a4efad0b-d928-43fe-8690-ae970e70eb50",
    "outputId": "8f372960-f86d-4957-ed49-acdd0a200735"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCFI</th>\n",
       "      <th>코로나확진자</th>\n",
       "      <th>환율</th>\n",
       "      <th>WTI유가</th>\n",
       "      <th>나프타유가</th>\n",
       "      <th>고유황중유가</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>주차</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-52</th>\n",
       "      <td>1759.57</td>\n",
       "      <td>27732700.0</td>\n",
       "      <td>1314.16</td>\n",
       "      <td>73.81</td>\n",
       "      <td>74.1325</td>\n",
       "      <td>69.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-52</th>\n",
       "      <td>1759.57</td>\n",
       "      <td>27732700.0</td>\n",
       "      <td>1314.16</td>\n",
       "      <td>73.69</td>\n",
       "      <td>74.1325</td>\n",
       "      <td>69.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-52</th>\n",
       "      <td>1759.57</td>\n",
       "      <td>27732700.0</td>\n",
       "      <td>1253.50</td>\n",
       "      <td>73.81</td>\n",
       "      <td>74.1325</td>\n",
       "      <td>69.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-52</th>\n",
       "      <td>1759.57</td>\n",
       "      <td>27732700.0</td>\n",
       "      <td>1253.50</td>\n",
       "      <td>73.69</td>\n",
       "      <td>74.1325</td>\n",
       "      <td>69.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-52</th>\n",
       "      <td>1759.57</td>\n",
       "      <td>263390.0</td>\n",
       "      <td>1314.16</td>\n",
       "      <td>73.81</td>\n",
       "      <td>74.1325</td>\n",
       "      <td>69.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-52</th>\n",
       "      <td>1759.57</td>\n",
       "      <td>263390.0</td>\n",
       "      <td>1314.16</td>\n",
       "      <td>73.69</td>\n",
       "      <td>74.1325</td>\n",
       "      <td>69.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-52</th>\n",
       "      <td>1759.57</td>\n",
       "      <td>263390.0</td>\n",
       "      <td>1253.50</td>\n",
       "      <td>73.81</td>\n",
       "      <td>74.1325</td>\n",
       "      <td>69.605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SCFI      코로나확진자       환율  WTI유가    나프타유가  고유황중유가\n",
       "주차                                                           \n",
       "2023-52  1759.57  27732700.0  1314.16  73.81  74.1325  69.605\n",
       "2023-52  1759.57  27732700.0  1314.16  73.69  74.1325  69.605\n",
       "2023-52  1759.57  27732700.0  1253.50  73.81  74.1325  69.605\n",
       "2023-52  1759.57  27732700.0  1253.50  73.69  74.1325  69.605\n",
       "2023-52  1759.57    263390.0  1314.16  73.81  74.1325  69.605\n",
       "2023-52  1759.57    263390.0  1314.16  73.69  74.1325  69.605\n",
       "2023-52  1759.57    263390.0  1253.50  73.81  74.1325  69.605"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 겹치는거 행 삭제\n",
    "df.iloc[563:570]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d3b5e6bc-116c-43da-838f-276a30b6f2d1",
   "metadata": {
    "id": "d3b5e6bc-116c-43da-838f-276a30b6f2d1"
   },
   "outputs": [],
   "source": [
    "df.drop(df.index[563:570], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ad621cc0-b871-46ce-b58d-d94f1f89af88",
   "metadata": {
    "id": "ad621cc0-b871-46ce-b58d-d94f1f89af88",
    "outputId": "573cf35c-6ce3-40e7-f038-c9a5300df853"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCFI</th>\n",
       "      <th>코로나확진자</th>\n",
       "      <th>환율</th>\n",
       "      <th>WTI유가</th>\n",
       "      <th>나프타유가</th>\n",
       "      <th>고유황중유가</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>주차</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-1</th>\n",
       "      <td>1148.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1056.49</td>\n",
       "      <td>93.56</td>\n",
       "      <td>106.6980</td>\n",
       "      <td>96.1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-2</th>\n",
       "      <td>1232.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1058.35</td>\n",
       "      <td>95.56</td>\n",
       "      <td>105.0360</td>\n",
       "      <td>97.7760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-3</th>\n",
       "      <td>1245.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1075.58</td>\n",
       "      <td>95.88</td>\n",
       "      <td>103.4800</td>\n",
       "      <td>97.2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-4</th>\n",
       "      <td>1227.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1095.19</td>\n",
       "      <td>97.77</td>\n",
       "      <td>106.6620</td>\n",
       "      <td>97.4920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-5</th>\n",
       "      <td>1219.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1096.00</td>\n",
       "      <td>95.72</td>\n",
       "      <td>108.1780</td>\n",
       "      <td>98.5660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-15</th>\n",
       "      <td>1757.04</td>\n",
       "      <td>39459.0</td>\n",
       "      <td>1374.30</td>\n",
       "      <td>83.14</td>\n",
       "      <td>74.9875</td>\n",
       "      <td>79.6475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-16</th>\n",
       "      <td>1769.54</td>\n",
       "      <td>31841.0</td>\n",
       "      <td>1376.43</td>\n",
       "      <td>83.85</td>\n",
       "      <td>74.3400</td>\n",
       "      <td>80.8120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-17</th>\n",
       "      <td>1940.63</td>\n",
       "      <td>34278.0</td>\n",
       "      <td>1354.63</td>\n",
       "      <td>78.11</td>\n",
       "      <td>75.0220</td>\n",
       "      <td>80.4920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-19</th>\n",
       "      <td>2305.79</td>\n",
       "      <td>33678.0</td>\n",
       "      <td>1351.76</td>\n",
       "      <td>80.06</td>\n",
       "      <td>71.8160</td>\n",
       "      <td>81.2640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-20</th>\n",
       "      <td>2520.76</td>\n",
       "      <td>36014.0</td>\n",
       "      <td>1365.93</td>\n",
       "      <td>77.72</td>\n",
       "      <td>70.4220</td>\n",
       "      <td>79.8220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            SCFI   코로나확진자       환율  WTI유가     나프타유가   고유황중유가\n",
       "주차                                                          \n",
       "2013-1   1148.08      0.0  1056.49  93.56  106.6980  96.1060\n",
       "2013-2   1232.35      0.0  1058.35  95.56  105.0360  97.7760\n",
       "2013-3   1245.84      0.0  1075.58  95.88  103.4800  97.2140\n",
       "2013-4   1227.84      0.0  1095.19  97.77  106.6620  97.4920\n",
       "2013-5   1219.39      0.0  1096.00  95.72  108.1780  98.5660\n",
       "...          ...      ...      ...    ...       ...      ...\n",
       "2024-15  1757.04  39459.0  1374.30  83.14   74.9875  79.6475\n",
       "2024-16  1769.54  31841.0  1376.43  83.85   74.3400  80.8120\n",
       "2024-17  1940.63  34278.0  1354.63  78.11   75.0220  80.4920\n",
       "2024-19  2305.79  33678.0  1351.76  80.06   71.8160  81.2640\n",
       "2024-20  2520.76  36014.0  1365.93  77.72   70.4220  79.8220\n",
       "\n",
       "[581 rows x 6 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ce382654-6420-4a7b-8976-efd2b70541a4",
   "metadata": {
    "id": "ce382654-6420-4a7b-8976-efd2b70541a4"
   },
   "outputs": [],
   "source": [
    "df.drop('환율', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4ac55f20-946a-4316-a829-fa960b77cf17",
   "metadata": {
    "id": "4ac55f20-946a-4316-a829-fa960b77cf17",
    "outputId": "2378691b-d615-4813-be20-4e0633405a00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCFI</th>\n",
       "      <th>코로나확진자</th>\n",
       "      <th>WTI유가</th>\n",
       "      <th>나프타유가</th>\n",
       "      <th>고유황중유가</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>주차</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-1</th>\n",
       "      <td>1148.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.56</td>\n",
       "      <td>106.6980</td>\n",
       "      <td>96.1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-2</th>\n",
       "      <td>1232.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.56</td>\n",
       "      <td>105.0360</td>\n",
       "      <td>97.7760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-3</th>\n",
       "      <td>1245.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.88</td>\n",
       "      <td>103.4800</td>\n",
       "      <td>97.2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-4</th>\n",
       "      <td>1227.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.77</td>\n",
       "      <td>106.6620</td>\n",
       "      <td>97.4920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-5</th>\n",
       "      <td>1219.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.72</td>\n",
       "      <td>108.1780</td>\n",
       "      <td>98.5660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-15</th>\n",
       "      <td>1757.04</td>\n",
       "      <td>39459.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>74.9875</td>\n",
       "      <td>79.6475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-16</th>\n",
       "      <td>1769.54</td>\n",
       "      <td>31841.0</td>\n",
       "      <td>83.85</td>\n",
       "      <td>74.3400</td>\n",
       "      <td>80.8120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-17</th>\n",
       "      <td>1940.63</td>\n",
       "      <td>34278.0</td>\n",
       "      <td>78.11</td>\n",
       "      <td>75.0220</td>\n",
       "      <td>80.4920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-19</th>\n",
       "      <td>2305.79</td>\n",
       "      <td>33678.0</td>\n",
       "      <td>80.06</td>\n",
       "      <td>71.8160</td>\n",
       "      <td>81.2640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-20</th>\n",
       "      <td>2520.76</td>\n",
       "      <td>36014.0</td>\n",
       "      <td>77.72</td>\n",
       "      <td>70.4220</td>\n",
       "      <td>79.8220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            SCFI   코로나확진자  WTI유가     나프타유가   고유황중유가\n",
       "주차                                                 \n",
       "2013-1   1148.08      0.0  93.56  106.6980  96.1060\n",
       "2013-2   1232.35      0.0  95.56  105.0360  97.7760\n",
       "2013-3   1245.84      0.0  95.88  103.4800  97.2140\n",
       "2013-4   1227.84      0.0  97.77  106.6620  97.4920\n",
       "2013-5   1219.39      0.0  95.72  108.1780  98.5660\n",
       "...          ...      ...    ...       ...      ...\n",
       "2024-15  1757.04  39459.0  83.14   74.9875  79.6475\n",
       "2024-16  1769.54  31841.0  83.85   74.3400  80.8120\n",
       "2024-17  1940.63  34278.0  78.11   75.0220  80.4920\n",
       "2024-19  2305.79  33678.0  80.06   71.8160  81.2640\n",
       "2024-20  2520.76  36014.0  77.72   70.4220  79.8220\n",
       "\n",
       "[581 rows x 5 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f87b4988-49e5-4c6b-9758-f4821a60385a",
   "metadata": {
    "id": "f87b4988-49e5-4c6b-9758-f4821a60385a"
   },
   "outputs": [],
   "source": [
    "X = df\n",
    "Y = df['SCFI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "26dce61d-f214-427c-93b3-4b83482a18d2",
   "metadata": {
    "id": "26dce61d-f214-427c-93b3-4b83482a18d2",
    "outputId": "03c4b9f5-cf13-4622-c4ca-2118ffd2355d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCFI</th>\n",
       "      <th>코로나확진자</th>\n",
       "      <th>WTI유가</th>\n",
       "      <th>나프타유가</th>\n",
       "      <th>고유황중유가</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>주차</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-1</th>\n",
       "      <td>1148.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.56</td>\n",
       "      <td>106.6980</td>\n",
       "      <td>96.1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-2</th>\n",
       "      <td>1232.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.56</td>\n",
       "      <td>105.0360</td>\n",
       "      <td>97.7760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-3</th>\n",
       "      <td>1245.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.88</td>\n",
       "      <td>103.4800</td>\n",
       "      <td>97.2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-4</th>\n",
       "      <td>1227.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.77</td>\n",
       "      <td>106.6620</td>\n",
       "      <td>97.4920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-5</th>\n",
       "      <td>1219.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.72</td>\n",
       "      <td>108.1780</td>\n",
       "      <td>98.5660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-15</th>\n",
       "      <td>1757.04</td>\n",
       "      <td>39459.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>74.9875</td>\n",
       "      <td>79.6475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-16</th>\n",
       "      <td>1769.54</td>\n",
       "      <td>31841.0</td>\n",
       "      <td>83.85</td>\n",
       "      <td>74.3400</td>\n",
       "      <td>80.8120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-17</th>\n",
       "      <td>1940.63</td>\n",
       "      <td>34278.0</td>\n",
       "      <td>78.11</td>\n",
       "      <td>75.0220</td>\n",
       "      <td>80.4920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-19</th>\n",
       "      <td>2305.79</td>\n",
       "      <td>33678.0</td>\n",
       "      <td>80.06</td>\n",
       "      <td>71.8160</td>\n",
       "      <td>81.2640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-20</th>\n",
       "      <td>2520.76</td>\n",
       "      <td>36014.0</td>\n",
       "      <td>77.72</td>\n",
       "      <td>70.4220</td>\n",
       "      <td>79.8220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            SCFI   코로나확진자  WTI유가     나프타유가   고유황중유가\n",
       "주차                                                 \n",
       "2013-1   1148.08      0.0  93.56  106.6980  96.1060\n",
       "2013-2   1232.35      0.0  95.56  105.0360  97.7760\n",
       "2013-3   1245.84      0.0  95.88  103.4800  97.2140\n",
       "2013-4   1227.84      0.0  97.77  106.6620  97.4920\n",
       "2013-5   1219.39      0.0  95.72  108.1780  98.5660\n",
       "...          ...      ...    ...       ...      ...\n",
       "2024-15  1757.04  39459.0  83.14   74.9875  79.6475\n",
       "2024-16  1769.54  31841.0  83.85   74.3400  80.8120\n",
       "2024-17  1940.63  34278.0  78.11   75.0220  80.4920\n",
       "2024-19  2305.79  33678.0  80.06   71.8160  81.2640\n",
       "2024-20  2520.76  36014.0  77.72   70.4220  79.8220\n",
       "\n",
       "[581 rows x 5 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e7b478c-cd65-4eae-880d-6602ba2c9108",
   "metadata": {
    "id": "0e7b478c-cd65-4eae-880d-6602ba2c9108"
   },
   "outputs": [],
   "source": [
    "# 데이터 정규화\n",
    "scaler_X = RobustScaler()\n",
    "scaled_X = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_Y = RobustScaler()\n",
    "scaled_Y = scaler_Y.fit_transform(Y.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be08ebd5-7ab7-42cd-8989-6ce0b15422fa",
   "metadata": {
    "id": "be08ebd5-7ab7-42cd-8989-6ce0b15422fa",
    "outputId": "0121c5f1-ed2a-44f7-a598-c57888bbc806",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 7.8802 - mae: 1.3620 - val_loss: 0.4271 - val_mae: 0.3772\n",
      "Epoch 2/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5020 - mae: 0.3849 - val_loss: 0.1266 - val_mae: 0.2122\n",
      "Epoch 3/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1818 - mae: 0.2276 - val_loss: 0.0741 - val_mae: 0.1973\n",
      "Epoch 4/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2955 - mae: 0.3193 - val_loss: 0.0703 - val_mae: 0.1737\n",
      "Epoch 5/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1545 - mae: 0.2337 - val_loss: 0.0802 - val_mae: 0.1746\n",
      "Epoch 6/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0997 - mae: 0.1973 - val_loss: 0.0435 - val_mae: 0.1368\n",
      "Epoch 7/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1436 - mae: 0.2366 - val_loss: 0.0455 - val_mae: 0.1355\n",
      "Epoch 8/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1448 - mae: 0.2117 - val_loss: 0.0725 - val_mae: 0.1652\n",
      "Epoch 9/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1506 - mae: 0.2101 - val_loss: 0.1215 - val_mae: 0.1861\n",
      "Epoch 10/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1616 - mae: 0.2133 - val_loss: 0.0588 - val_mae: 0.1719\n",
      "Epoch 11/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1048 - mae: 0.1795 - val_loss: 0.0343 - val_mae: 0.1125\n",
      "Epoch 12/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0751 - mae: 0.1491 - val_loss: 0.0180 - val_mae: 0.0871\n",
      "Epoch 13/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1130 - mae: 0.1815 - val_loss: 0.0382 - val_mae: 0.1485\n",
      "Epoch 14/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1441 - mae: 0.1908 - val_loss: 0.0242 - val_mae: 0.1025\n",
      "Epoch 15/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1043 - mae: 0.1791 - val_loss: 0.0212 - val_mae: 0.0901\n",
      "Epoch 16/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0710 - mae: 0.1331 - val_loss: 0.0208 - val_mae: 0.1018\n",
      "Epoch 17/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1358 - mae: 0.1794 - val_loss: 0.0551 - val_mae: 0.1205\n",
      "Epoch 18/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0957 - mae: 0.1692 - val_loss: 0.0589 - val_mae: 0.1707\n",
      "Epoch 19/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0908 - mae: 0.1643 - val_loss: 0.0348 - val_mae: 0.1045\n",
      "Epoch 20/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1336 - mae: 0.1788 - val_loss: 0.0158 - val_mae: 0.0750\n",
      "Epoch 21/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0669 - mae: 0.1273 - val_loss: 0.0507 - val_mae: 0.1290\n",
      "Epoch 22/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1026 - mae: 0.1630 - val_loss: 0.0175 - val_mae: 0.0853\n",
      "Epoch 23/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0838 - mae: 0.1353 - val_loss: 0.1106 - val_mae: 0.1776\n",
      "Epoch 24/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0914 - mae: 0.1382 - val_loss: 0.0129 - val_mae: 0.0708\n",
      "Epoch 25/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1072 - mae: 0.1617 - val_loss: 0.1209 - val_mae: 0.1739\n",
      "Epoch 26/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0948 - mae: 0.1537 - val_loss: 0.0311 - val_mae: 0.0809\n",
      "Epoch 27/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0778 - mae: 0.1525 - val_loss: 0.0287 - val_mae: 0.0974\n",
      "Epoch 28/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0688 - mae: 0.1213 - val_loss: 0.0268 - val_mae: 0.0787\n",
      "Epoch 29/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0760 - mae: 0.1275 - val_loss: 0.0459 - val_mae: 0.0983\n",
      "Epoch 30/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1211 - mae: 0.1650 - val_loss: 0.0489 - val_mae: 0.1210\n",
      "Epoch 31/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0890 - mae: 0.1320 - val_loss: 0.0159 - val_mae: 0.0824\n",
      "Epoch 32/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0938 - mae: 0.1633 - val_loss: 0.0319 - val_mae: 0.0882\n",
      "Epoch 33/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0699 - mae: 0.1238 - val_loss: 0.0150 - val_mae: 0.0673\n",
      "Epoch 34/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0729 - mae: 0.1283 - val_loss: 0.0164 - val_mae: 0.0662\n",
      "Epoch 35/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0822 - mae: 0.1312 - val_loss: 0.0129 - val_mae: 0.0646\n",
      "Epoch 36/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2440 - mae: 0.2229 - val_loss: 0.0211 - val_mae: 0.0686\n",
      "Epoch 37/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0772 - mae: 0.1464 - val_loss: 0.0725 - val_mae: 0.1263\n",
      "Epoch 38/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0840 - mae: 0.1496 - val_loss: 0.1015 - val_mae: 0.1433\n",
      "Epoch 39/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0496 - mae: 0.1083 - val_loss: 0.0260 - val_mae: 0.0689\n",
      "Epoch 40/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1046 - mae: 0.1508 - val_loss: 0.0273 - val_mae: 0.0974\n",
      "Epoch 41/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0784 - mae: 0.1344 - val_loss: 0.1227 - val_mae: 0.2046\n",
      "Epoch 42/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1594 - mae: 0.1783 - val_loss: 0.0093 - val_mae: 0.0559\n",
      "Epoch 43/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1349 - mae: 0.1818 - val_loss: 0.0312 - val_mae: 0.0760\n",
      "Epoch 44/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1132 - mae: 0.1666 - val_loss: 0.0153 - val_mae: 0.0817\n",
      "Epoch 45/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0934 - mae: 0.1562 - val_loss: 0.0097 - val_mae: 0.0557\n",
      "Epoch 46/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0469 - mae: 0.1122 - val_loss: 0.0203 - val_mae: 0.0748\n",
      "Epoch 47/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0561 - mae: 0.1164 - val_loss: 0.0201 - val_mae: 0.0633\n",
      "Epoch 48/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0736 - mae: 0.1269 - val_loss: 0.0218 - val_mae: 0.0830\n",
      "Epoch 49/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1490 - mae: 0.1860 - val_loss: 0.0106 - val_mae: 0.0616\n",
      "Epoch 50/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1502 - mae: 0.1812 - val_loss: 0.0079 - val_mae: 0.0535\n",
      "Epoch 51/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0545 - mae: 0.1224 - val_loss: 0.0307 - val_mae: 0.1126\n",
      "Epoch 52/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0688 - mae: 0.1311 - val_loss: 0.0362 - val_mae: 0.1264\n",
      "Epoch 53/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2242 - mae: 0.2060 - val_loss: 0.0149 - val_mae: 0.0668\n",
      "Epoch 54/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1236 - mae: 0.1686 - val_loss: 0.0066 - val_mae: 0.0487\n",
      "Epoch 55/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0890 - mae: 0.1484 - val_loss: 0.0448 - val_mae: 0.1411\n",
      "Epoch 56/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0616 - mae: 0.1294 - val_loss: 0.0409 - val_mae: 0.1037\n",
      "Epoch 57/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1045 - mae: 0.1606 - val_loss: 0.0929 - val_mae: 0.1630\n",
      "Epoch 58/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1184 - mae: 0.1666 - val_loss: 0.0067 - val_mae: 0.0522\n",
      "Epoch 59/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1073 - mae: 0.1417 - val_loss: 0.0456 - val_mae: 0.1250\n",
      "Epoch 60/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1005 - mae: 0.1548 - val_loss: 0.0165 - val_mae: 0.0934\n",
      "Epoch 61/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0437 - mae: 0.1143 - val_loss: 0.0117 - val_mae: 0.0871\n",
      "Epoch 62/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0764 - mae: 0.1410 - val_loss: 0.0116 - val_mae: 0.0561\n",
      "Epoch 63/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0850 - mae: 0.1574 - val_loss: 0.0088 - val_mae: 0.0603\n",
      "Epoch 64/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0525 - mae: 0.1246 - val_loss: 0.0671 - val_mae: 0.1466\n",
      "Epoch 65/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0683 - mae: 0.1390 - val_loss: 0.0065 - val_mae: 0.0475\n",
      "Epoch 66/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0867 - mae: 0.1430 - val_loss: 0.0143 - val_mae: 0.0740\n",
      "Epoch 67/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0868 - mae: 0.1343 - val_loss: 0.1486 - val_mae: 0.1923\n",
      "Epoch 68/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0714 - mae: 0.1501 - val_loss: 0.0114 - val_mae: 0.0489\n",
      "Epoch 69/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0460 - mae: 0.1197 - val_loss: 0.1288 - val_mae: 0.1632\n",
      "Epoch 70/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1016 - mae: 0.1517 - val_loss: 0.0080 - val_mae: 0.0545\n",
      "Epoch 71/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1185 - mae: 0.1624 - val_loss: 0.0092 - val_mae: 0.0658\n",
      "Epoch 72/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0630 - mae: 0.1221 - val_loss: 0.0414 - val_mae: 0.0915\n",
      "Epoch 73/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0528 - mae: 0.1193 - val_loss: 0.0068 - val_mae: 0.0398\n",
      "Epoch 74/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0840 - mae: 0.1365 - val_loss: 0.0508 - val_mae: 0.1608\n",
      "Epoch 75/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1486 - mae: 0.1765 - val_loss: 0.0493 - val_mae: 0.1314\n",
      "Epoch 76/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0844 - mae: 0.1356 - val_loss: 0.0562 - val_mae: 0.1211\n",
      "Epoch 77/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0864 - mae: 0.1521 - val_loss: 0.0221 - val_mae: 0.1103\n",
      "Epoch 78/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0661 - mae: 0.1307 - val_loss: 0.0179 - val_mae: 0.0695\n",
      "Epoch 79/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0509 - mae: 0.1160 - val_loss: 0.0304 - val_mae: 0.1008\n",
      "Epoch 80/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0620 - mae: 0.1384 - val_loss: 0.0205 - val_mae: 0.0990\n",
      "Epoch 81/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1003 - mae: 0.1676 - val_loss: 0.0445 - val_mae: 0.1126\n",
      "Epoch 82/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0831 - mae: 0.1425 - val_loss: 0.0055 - val_mae: 0.0353\n",
      "Epoch 83/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0680 - mae: 0.1236 - val_loss: 0.0085 - val_mae: 0.0636\n",
      "Epoch 84/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0559 - mae: 0.1221 - val_loss: 0.0106 - val_mae: 0.0572\n",
      "Epoch 85/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0703 - mae: 0.1297 - val_loss: 0.0302 - val_mae: 0.1079\n",
      "Epoch 86/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0890 - mae: 0.1438 - val_loss: 0.0177 - val_mae: 0.0584\n",
      "Epoch 87/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0929 - mae: 0.1528 - val_loss: 0.0061 - val_mae: 0.0473\n",
      "Epoch 88/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0554 - mae: 0.1230 - val_loss: 0.0079 - val_mae: 0.0503\n",
      "Epoch 89/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0872 - mae: 0.1400 - val_loss: 0.0806 - val_mae: 0.1428\n",
      "Epoch 90/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0885 - mae: 0.1713 - val_loss: 0.0205 - val_mae: 0.0702\n",
      "Epoch 91/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0876 - mae: 0.1483 - val_loss: 0.0515 - val_mae: 0.1071\n",
      "Epoch 92/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0486 - mae: 0.1008 - val_loss: 0.0089 - val_mae: 0.0529\n",
      "Epoch 93/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0611 - mae: 0.1263 - val_loss: 0.0123 - val_mae: 0.0624\n",
      "Epoch 94/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0712 - mae: 0.1336 - val_loss: 0.0111 - val_mae: 0.0597\n",
      "Epoch 95/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1315 - mae: 0.1707 - val_loss: 0.0088 - val_mae: 0.0561\n",
      "Epoch 96/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0464 - mae: 0.1097 - val_loss: 0.0317 - val_mae: 0.0879\n",
      "Epoch 97/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0794 - mae: 0.1357 - val_loss: 0.1118 - val_mae: 0.1711\n",
      "Epoch 98/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0644 - mae: 0.1382 - val_loss: 0.0106 - val_mae: 0.0789\n",
      "Epoch 99/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0434 - mae: 0.1080 - val_loss: 0.0098 - val_mae: 0.0577\n",
      "Epoch 100/100\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0811 - mae: 0.1406 - val_loss: 0.0466 - val_mae: 0.1006\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    }
   ],
   "source": [
    "# 데이터셋을 훈련, 검증 및 테스트 세트로 분할\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(scaled_X, scaled_Y, test_size=0.4, random_state=42)\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# GRU 입력 형태로 데이터 변환 [samples, WINDOW steps = 1 , features]\n",
    "x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_valid = x_valid.reshape((x_valid.shape[0], 1, x_valid.shape[1]))\n",
    "x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "# GRU 모델 생성\n",
    "model = Sequential([\n",
    "    Input(shape=(1, x_train.shape[2])),\n",
    "    GRU(50, return_sequences=True),\n",
    "    GRU(50, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "# Model configuration\n",
    "model = Sequential()\n",
    "model.add(GRU(50, activation='relu', input_shape=(time_steps, X_seq.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(50, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(future_steps))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=100, validation_split=0.2)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=100, batch_size=1, verbose=1)\n",
    "\n",
    "# 모델 예측\n",
    "train_predict = model.predict(x_train)\n",
    "valid_predict = model.predict(x_valid)\n",
    "test_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d315502d-ef64-44bd-91ea-8f3f167beee9",
   "metadata": {
    "id": "d315502d-ef64-44bd-91ea-8f3f167beee9",
    "outputId": "61699d7a-8163-4013-b524-decc24611492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 0.079\n",
      "R2 Score: 0.997\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "mae = mean_absolute_error(y_test, test_predict)\n",
    "r2 = r2_score(y_test, test_predict)\n",
    "\n",
    "print(f'Test MAE: {mae:.3f}')\n",
    "print(f'R2 Score: {r2:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbdc6258-54c3-4f47-a2ec-9d2fe6ca2fd9",
   "metadata": {
    "id": "dbdc6258-54c3-4f47-a2ec-9d2fe6ca2fd9",
    "outputId": "fd967ce3-37a9-4dfd-b0e5-1474c585b96f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Predicted Y (actual): [[2809.776]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RobustScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 새로운 입력 데이터 생성 (예시 데이터,5월 31일 SCFI, 코로나 신규확진자, WTI, 나프타, 고유황중유)\n",
    "new_X = np.array([[3044.77,75000, 75.57, 629.39, 600.62]])\n",
    "new_X_scaled = scaler_X.transform(new_X)  # 입력 데이터를 정규화\n",
    "new_X_reshaped = new_X_scaled.reshape((new_X_scaled.shape[0], 1, new_X_scaled.shape[1]))  # 입력 데이터를 GRU 입력 형태로 변환\n",
    "\n",
    "# 예측 수행\n",
    "new_Y_pred = model.predict(new_X_reshaped)\n",
    "\n",
    "# 예측 값을 실제 값으로 변환\n",
    "new_Y_pred_actual = scaler_Y.inverse_transform(new_Y_pred.reshape(-1, 1))\n",
    "\n",
    "# 예측 결과 출력\n",
    "print(f\"Predicted Y (actual): {new_Y_pred_actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78c81d97-4404-45bd-ba54-a14251b0ea98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Model does not support predicting 4 steps in one go.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RobustScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get the latest value and scale it\n",
    "latest_value = df[['SCFI', '코로나확진자', 'WTI유가', '나프타유가', '고유황중유가']].values[-1]\n",
    "latest_value_scaled = scaler_X.transform(latest_value.reshape(1, -1))\n",
    "\n",
    "# Prepare the input for the GRU model\n",
    "current_input = latest_value_scaled.reshape((1, 1, latest_value_scaled.shape[1]))\n",
    "\n",
    "# Assuming the model is capable of predicting multiple future steps in one go\n",
    "future_steps = 1\n",
    "predicted = model.predict(current_input)\n",
    "\n",
    "# Check if the model can output the required number of future steps directly\n",
    "if predicted.shape[1] < future_steps:\n",
    "    print(f\"Model does not support predicting {future_steps} steps in one go.\")\n",
    "else:\n",
    "    future_predictions = predicted[0, :future_steps]\n",
    "\n",
    "    # Inverse transform the predictions\n",
    "    future_predictions = scaler_Y.inverse_transform(future_predictions.reshape(-1, 1))\n",
    "\n",
    "    # Print the predictions\n",
    "    print(f\"Future Predictions: {future_predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7a68965f-7330-4a43-8d57-6a01506f531a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 11.9288 - val_loss: 13.3660\n",
      "Epoch 2/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 10.6639 - val_loss: 11.0852\n",
      "Epoch 3/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.3663 - val_loss: 7.3260\n",
      "Epoch 4/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9393 - val_loss: 4.4125\n",
      "Epoch 5/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.1447 - val_loss: 1.7028\n",
      "Epoch 6/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6392 - val_loss: 1.3073\n",
      "Epoch 7/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0121 - val_loss: 1.0758\n",
      "Epoch 8/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8148 - val_loss: 0.9431\n",
      "Epoch 9/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7438 - val_loss: 0.7576\n",
      "Epoch 10/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6661 - val_loss: 0.6947\n",
      "Epoch 11/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5101 - val_loss: 0.5871\n",
      "Epoch 12/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4476 - val_loss: 0.5759\n",
      "Epoch 13/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4507 - val_loss: 0.7539\n",
      "Epoch 14/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6177 - val_loss: 0.5558\n",
      "Epoch 15/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3772 - val_loss: 0.4213\n",
      "Epoch 16/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3313 - val_loss: 0.3985\n",
      "Epoch 17/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3624 - val_loss: 0.4292\n",
      "Epoch 18/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2714 - val_loss: 0.3623\n",
      "Epoch 19/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2849 - val_loss: 0.3363\n",
      "Epoch 20/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3090 - val_loss: 0.3569\n",
      "Epoch 21/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2291 - val_loss: 0.3128\n",
      "Epoch 22/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2898 - val_loss: 0.3018\n",
      "Epoch 23/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2682 - val_loss: 0.3752\n",
      "Epoch 24/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3269 - val_loss: 0.2730\n",
      "Epoch 25/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3054 - val_loss: 0.2640\n",
      "Epoch 26/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2279 - val_loss: 0.3611\n",
      "Epoch 27/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2843 - val_loss: 0.3809\n",
      "Epoch 28/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2578 - val_loss: 0.2588\n",
      "Epoch 29/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3209 - val_loss: 0.2709\n",
      "Epoch 30/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2296 - val_loss: 0.3793\n",
      "Epoch 31/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2161 - val_loss: 0.2500\n",
      "Epoch 32/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2286 - val_loss: 0.3395\n",
      "Epoch 33/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2546 - val_loss: 0.2911\n",
      "Epoch 34/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2114 - val_loss: 0.2778\n",
      "Epoch 35/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2154 - val_loss: 0.2298\n",
      "Epoch 36/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1850 - val_loss: 0.2358\n",
      "Epoch 37/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2047 - val_loss: 0.2241\n",
      "Epoch 38/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1897 - val_loss: 0.2083\n",
      "Epoch 39/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1787 - val_loss: 0.2183\n",
      "Epoch 40/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1673 - val_loss: 0.2140\n",
      "Epoch 41/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1581 - val_loss: 0.2318\n",
      "Epoch 42/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1982 - val_loss: 0.1935\n",
      "Epoch 43/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1659 - val_loss: 0.1913\n",
      "Epoch 44/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1699 - val_loss: 0.1931\n",
      "Epoch 45/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1770 - val_loss: 0.2114\n",
      "Epoch 46/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1914 - val_loss: 0.1964\n",
      "Epoch 47/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1419 - val_loss: 0.1872\n",
      "Epoch 48/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1498 - val_loss: 0.1915\n",
      "Epoch 49/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1343 - val_loss: 0.1821\n",
      "Epoch 50/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1535 - val_loss: 0.1812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RobustScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step\n",
      "Future Predictions: [[1886.7096]\n",
      " [2201.0598]\n",
      " [2310.5515]\n",
      " [1940.7665]\n",
      " [2365.9124]\n",
      " [2330.4773]\n",
      " [2215.8489]\n",
      " [2216.1416]]\n"
     ]
    }
   ],
   "source": [
    "# Create sequences for multi-step prediction\n",
    "def create_sequences(X, y, time_steps=1, future_steps=4):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps - future_steps + 1):\n",
    "        Xs.append(X[i:(i + time_steps)])\n",
    "        ys.append(y[(i + time_steps):(i + time_steps + future_steps)])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 1\n",
    "future_steps = 1\n",
    "\n",
    "X_seq, y_seq = create_sequences(scaled_X, scaled_Y, time_steps, future_steps)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the GRU model\n",
    "model = Sequential()\n",
    "model.add(GRU(50, activation='relu', input_shape=(time_steps, X_seq.shape[2])))\n",
    "model.add(Dense(future_steps))  # Output layer for multiple future steps\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Get the latest value and scale it\n",
    "latest_value = df[['SCFI', '코로나확진자', 'WTI유가', '나프타유가', '고유황중유가']].values[-time_steps:]\n",
    "latest_value_scaled = scaler_X.transform(latest_value)\n",
    "\n",
    "# Prepare the input for the GRU model\n",
    "current_input = latest_value_scaled.reshape((1, time_steps, latest_value_scaled.shape[1]))\n",
    "\n",
    "# Predict multiple future steps\n",
    "predicted = model.predict(current_input)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "future_predictions = scaler_Y.inverse_transform(predicted.reshape(-1, 1))\n",
    "\n",
    "# Print the predictions\n",
    "print(f\"Future Predictions: {future_predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07d6d246-7ac1-4ffc-bd28-3266c115b416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Future Predictions: [[2153.2776]\n",
      " [2207.6052]\n",
      " [2262.079 ]\n",
      " [2495.9204]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RobustScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "\n",
    "# Get the latest value and scale it\n",
    "latest_value = df[['SCFI', '코로나확진자', 'WTI유가', '나프타유가', '고유황중유가']].values[-time_steps:]\n",
    "latest_value_scaled = scaler_X.transform(latest_value)\n",
    "\n",
    "# Prepare the input for the GRU model\n",
    "current_input = latest_value_scaled.reshape((1, time_steps, latest_value_scaled.shape[1]))\n",
    "\n",
    "# Predict multiple future steps\n",
    "predicted = model.predict(current_input)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "future_predictions = scaler_Y.inverse_transform(predicted.reshape(-1, 1))\n",
    "\n",
    "# Print the predictions\n",
    "print(f\"Future Predictions: {future_predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "07c8d1f4-645f-4c80-9618-a679dae4455f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "[[1742.8596]\n",
      " [1787.5312]\n",
      " [1741.7887]\n",
      " [1719.3794]\n",
      " [1893.1537]\n",
      " [1970.565 ]\n",
      " [1884.3944]\n",
      " [2090.924 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RobustScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 마지막 14번째 행부터 10개의 행을 타임 스텝으로 사용\n",
    "start_index = -16\n",
    "end_index = start_index + time_steps\n",
    "latest_value = df[['SCFI', '코로나확진자', 'WTI유가', '나프타유가', '고유황중유가']].values[start_index:end_index]\n",
    "latest_value_scaled = scaler_X.transform(latest_value)\n",
    "current_input = latest_value_scaled.reshape((1, time_steps, latest_value_scaled.shape[1]))\n",
    "\n",
    "# 미래 4개 값 예측\n",
    "predicted_future = model.predict(current_input)\n",
    "predicted_future_inv = scaler_Y.inverse_transform(predicted_future.reshape(-1, 1))\n",
    "print(predicted_future_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a2f62a3d-73a2-4c84-aaab-a14c5339f58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 139.115\n",
      "R2 Score: 0.418\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "mae = mean_absolute_error(df['SCFI'][-8:], predicted_future_inv)\n",
    "r2 = r2_score(df['SCFI'][-8:], predicted_future_inv)\n",
    "\n",
    "print(f'Test MAE: {mae:.3f}')\n",
    "print(f'R2 Score: {r2:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f822a6e2-75f5-401b-a706-f27ccad5f17a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 91ms/step - loss: 13.2667 - val_loss: 12.4855\n",
      "Epoch 2/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.9046 - val_loss: 9.2503\n",
      "Epoch 3/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.2887 - val_loss: 4.4417\n",
      "Epoch 4/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.0107 - val_loss: 2.0464\n",
      "Epoch 5/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9986 - val_loss: 0.9267\n",
      "Epoch 6/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4718 - val_loss: 0.8170\n",
      "Epoch 7/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3138 - val_loss: 0.7323\n",
      "Epoch 8/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0965 - val_loss: 0.7087\n",
      "Epoch 9/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1373 - val_loss: 0.7206\n",
      "Epoch 10/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3520 - val_loss: 0.6285\n",
      "Epoch 11/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9501 - val_loss: 0.6180\n",
      "Epoch 12/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0971 - val_loss: 0.7554\n",
      "Epoch 13/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1613 - val_loss: 0.5909\n",
      "Epoch 14/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9152 - val_loss: 0.7628\n",
      "Epoch 15/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0722 - val_loss: 0.6644\n",
      "Epoch 16/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2839 - val_loss: 0.5130\n",
      "Epoch 17/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7559 - val_loss: 0.4959\n",
      "Epoch 18/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7013 - val_loss: 0.5372\n",
      "Epoch 19/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9414 - val_loss: 0.5274\n",
      "Epoch 20/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6280 - val_loss: 0.4814\n",
      "Epoch 21/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8201 - val_loss: 0.5030\n",
      "Epoch 22/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8935 - val_loss: 0.4865\n",
      "Epoch 23/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9293 - val_loss: 0.5191\n",
      "Epoch 24/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8951 - val_loss: 0.4419\n",
      "Epoch 25/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7701 - val_loss: 0.5538\n",
      "Epoch 26/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6876 - val_loss: 0.5507\n",
      "Epoch 27/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6656 - val_loss: 0.4009\n",
      "Epoch 28/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6303 - val_loss: 0.3955\n",
      "Epoch 29/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7784 - val_loss: 0.4738\n",
      "Epoch 30/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6232 - val_loss: 0.4707\n",
      "Epoch 31/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8068 - val_loss: 0.4659\n",
      "Epoch 32/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7017 - val_loss: 0.4418\n",
      "Epoch 33/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5994 - val_loss: 0.5825\n",
      "Epoch 34/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6734 - val_loss: 0.4112\n",
      "Epoch 35/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6836 - val_loss: 0.4687\n",
      "Epoch 36/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7727 - val_loss: 0.3568\n",
      "Epoch 37/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6040 - val_loss: 0.3190\n",
      "Epoch 38/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5448 - val_loss: 0.4870\n",
      "Epoch 39/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6048 - val_loss: 0.3466\n",
      "Epoch 40/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5358 - val_loss: 0.2608\n",
      "Epoch 41/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6147 - val_loss: 0.4568\n",
      "Epoch 42/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8570 - val_loss: 0.3661\n",
      "Epoch 43/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5549 - val_loss: 0.3413\n",
      "Epoch 44/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4772 - val_loss: 0.2696\n",
      "Epoch 45/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6412 - val_loss: 0.3712\n",
      "Epoch 46/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4795 - val_loss: 0.2554\n",
      "Epoch 47/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6116 - val_loss: 0.4793\n",
      "Epoch 48/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4924 - val_loss: 0.3300\n",
      "Epoch 49/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3892 - val_loss: 0.3015\n",
      "Epoch 50/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4479 - val_loss: 0.2448\n",
      "Epoch 51/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4784 - val_loss: 0.2287\n",
      "Epoch 52/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4307 - val_loss: 0.3691\n",
      "Epoch 53/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5160 - val_loss: 0.2819\n",
      "Epoch 54/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4102 - val_loss: 0.2635\n",
      "Epoch 55/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3998 - val_loss: 0.1941\n",
      "Epoch 56/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5220 - val_loss: 0.3571\n",
      "Epoch 57/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3755 - val_loss: 0.2348\n",
      "Epoch 58/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4068 - val_loss: 0.2316\n",
      "Epoch 59/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4702 - val_loss: 0.1730\n",
      "Epoch 60/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3989 - val_loss: 0.2316\n",
      "Epoch 61/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4601 - val_loss: 0.2604\n",
      "Epoch 62/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4907 - val_loss: 0.3182\n",
      "Epoch 63/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5560 - val_loss: 0.2018\n",
      "Epoch 64/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4435 - val_loss: 0.2985\n",
      "Epoch 65/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3587 - val_loss: 0.2264\n",
      "Epoch 66/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3884 - val_loss: 0.2190\n",
      "Epoch 67/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3644 - val_loss: 0.2486\n",
      "Epoch 68/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4158 - val_loss: 0.2176\n",
      "Epoch 69/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3418 - val_loss: 0.1931\n",
      "Epoch 70/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.3481 - val_loss: 0.2331\n",
      "Epoch 71/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3845 - val_loss: 0.2097\n",
      "Epoch 72/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3954 - val_loss: 0.1409\n",
      "Epoch 73/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3600 - val_loss: 0.1723\n",
      "Epoch 74/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4047 - val_loss: 0.2626\n",
      "Epoch 75/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3181 - val_loss: 0.2378\n",
      "Epoch 76/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3499 - val_loss: 0.1609\n",
      "Epoch 77/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.4100 - val_loss: 0.1392\n",
      "Epoch 78/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3342 - val_loss: 0.2041\n",
      "Epoch 79/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3896 - val_loss: 0.1544\n",
      "Epoch 80/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5206 - val_loss: 0.2045\n",
      "Epoch 81/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3739 - val_loss: 0.2211\n",
      "Epoch 82/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3498 - val_loss: 0.2164\n",
      "Epoch 83/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3684 - val_loss: 0.1668\n",
      "Epoch 84/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3576 - val_loss: 0.2246\n",
      "Epoch 85/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4728 - val_loss: 0.2766\n",
      "Epoch 86/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3614 - val_loss: 0.1646\n",
      "Epoch 87/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3550 - val_loss: 0.2567\n",
      "Epoch 88/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4588 - val_loss: 0.2107\n",
      "Epoch 89/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3333 - val_loss: 0.1368\n",
      "Epoch 90/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2774 - val_loss: 0.1539\n",
      "Epoch 91/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4698 - val_loss: 0.2176\n",
      "Epoch 92/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3325 - val_loss: 0.1627\n",
      "Epoch 93/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2976 - val_loss: 0.1553\n",
      "Epoch 94/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2736 - val_loss: 0.2968\n",
      "Epoch 95/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4239 - val_loss: 0.1520\n",
      "Epoch 96/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3624 - val_loss: 0.1147\n",
      "Epoch 97/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.4372 - val_loss: 0.2036\n",
      "Epoch 98/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2810 - val_loss: 0.2250\n",
      "Epoch 99/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2779 - val_loss: 0.1243\n",
      "Epoch 100/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3568 - val_loss: 0.1938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RobustScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step  \n",
      "Test MAE: 106.427\n",
      "Test R2 Score: 0.977\n"
     ]
    }
   ],
   "source": [
    "scaler_X = RobustScaler()\n",
    "scaled_X = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_Y = RobustScaler()\n",
    "scaled_Y = scaler_Y.fit_transform(Y.values.reshape(-1, 1))\n",
    "\n",
    "# Sequence creation function\n",
    "def create_sequences(X, Y, time_steps=1, future_steps=4):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps - future_steps + 1):\n",
    "        Xs.append(X[i:(i + time_steps)])\n",
    "        ys.append(Y[(i + time_steps):(i + time_steps + future_steps)])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 8\n",
    "future_steps = 8\n",
    "\n",
    "X_seq, y_seq = create_sequences(scaled_X, scaled_Y, time_steps, future_steps)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model configuration\n",
    "model = Sequential()\n",
    "model.add(GRU(50, activation='relu', input_shape=(time_steps, X_seq.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(50, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(future_steps))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=100, validation_split=0.2)\n",
    "\n",
    "# Use the last 16 rows of the dataframe for the prediction input\n",
    "start_index = -16\n",
    "end_index = start_index + time_steps\n",
    "latest_value = df[['SCFI', '코로나확진자', 'WTI유가', '나프타유가', '고유황중유가']].values[start_index:end_index]\n",
    "latest_value_scaled = scaler_X.transform(latest_value)\n",
    "current_input = latest_value_scaled.reshape((1, time_steps, latest_value_scaled.shape[1]))\n",
    "\n",
    "# Predict the future 8 values\n",
    "predicted_future = model.predict(current_input)\n",
    "predicted_future_inv = scaler_Y.inverse_transform(predicted_future.reshape(-1, 1))\n",
    "\n",
    "# Evaluate on the entire test set\n",
    "test_predict = model.predict(X_test)\n",
    "test_predict_inv = scaler_Y.inverse_transform(test_predict.reshape(-1, future_steps))\n",
    "y_test_inv = scaler_Y.inverse_transform(y_test.reshape(-1, future_steps))\n",
    "\n",
    "mae_test = mean_absolute_error(y_test_inv, test_predict_inv)\n",
    "r2_test = r2_score(y_test_inv, test_predict_inv)\n",
    "\n",
    "print(f'Test MAE: {mae_test:.3f}')\n",
    "print(f'Test R2 Score: {r2_test:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119e565-320d-4519-a078-b9d66fd4718b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
