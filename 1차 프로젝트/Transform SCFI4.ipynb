{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d5e66a-0726-415d-8fd9-5fd3217a7d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상관계수 만들기 OIL PRESENT, 나프타, 황중유, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e245ccfb-ca1e-4fc2-bd31-357493194bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, Dropout, Embedding\n",
    "from tensorflow.keras.layers import MultiHeadAttention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "230675c4-c907-45a4-8159-46a8f229432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"화이팅_ㅋ.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "370f2428-1bb0-4c89-91c1-6bc0a8df8c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>주차</th>\n",
       "      <th>SCFI</th>\n",
       "      <th>코로나확진자</th>\n",
       "      <th>환율</th>\n",
       "      <th>WTI유가</th>\n",
       "      <th>나프타유가</th>\n",
       "      <th>고유황중유가</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-1</td>\n",
       "      <td>1148.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1056.49</td>\n",
       "      <td>93.56</td>\n",
       "      <td>106.6980</td>\n",
       "      <td>96.1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-2</td>\n",
       "      <td>1232.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1058.35</td>\n",
       "      <td>95.56</td>\n",
       "      <td>105.0360</td>\n",
       "      <td>97.7760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-3</td>\n",
       "      <td>1245.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1075.58</td>\n",
       "      <td>95.88</td>\n",
       "      <td>103.4800</td>\n",
       "      <td>97.2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-4</td>\n",
       "      <td>1227.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1095.19</td>\n",
       "      <td>97.77</td>\n",
       "      <td>106.6620</td>\n",
       "      <td>97.4920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-5</td>\n",
       "      <td>1219.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1096.00</td>\n",
       "      <td>95.72</td>\n",
       "      <td>108.1780</td>\n",
       "      <td>98.5660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>2024-15</td>\n",
       "      <td>1757.04</td>\n",
       "      <td>39459.0</td>\n",
       "      <td>1374.30</td>\n",
       "      <td>83.14</td>\n",
       "      <td>74.9875</td>\n",
       "      <td>79.6475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>2024-16</td>\n",
       "      <td>1769.54</td>\n",
       "      <td>31841.0</td>\n",
       "      <td>1376.43</td>\n",
       "      <td>83.85</td>\n",
       "      <td>74.3400</td>\n",
       "      <td>80.8120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>2024-17</td>\n",
       "      <td>1940.63</td>\n",
       "      <td>34278.0</td>\n",
       "      <td>1354.63</td>\n",
       "      <td>78.11</td>\n",
       "      <td>75.0220</td>\n",
       "      <td>80.4920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>2024-19</td>\n",
       "      <td>2305.79</td>\n",
       "      <td>33678.0</td>\n",
       "      <td>1351.76</td>\n",
       "      <td>80.06</td>\n",
       "      <td>71.8160</td>\n",
       "      <td>81.2640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>2024-20</td>\n",
       "      <td>2520.76</td>\n",
       "      <td>36014.0</td>\n",
       "      <td>1365.93</td>\n",
       "      <td>77.72</td>\n",
       "      <td>70.4220</td>\n",
       "      <td>79.8220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>589 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          주차     SCFI   코로나확진자       환율  WTI유가     나프타유가   고유황중유가\n",
       "0     2013-1  1148.08      0.0  1056.49  93.56  106.6980  96.1060\n",
       "1     2013-2  1232.35      0.0  1058.35  95.56  105.0360  97.7760\n",
       "2     2013-3  1245.84      0.0  1075.58  95.88  103.4800  97.2140\n",
       "3     2013-4  1227.84      0.0  1095.19  97.77  106.6620  97.4920\n",
       "4     2013-5  1219.39      0.0  1096.00  95.72  108.1780  98.5660\n",
       "..       ...      ...      ...      ...    ...       ...      ...\n",
       "584  2024-15  1757.04  39459.0  1374.30  83.14   74.9875  79.6475\n",
       "585  2024-16  1769.54  31841.0  1376.43  83.85   74.3400  80.8120\n",
       "586  2024-17  1940.63  34278.0  1354.63  78.11   75.0220  80.4920\n",
       "587  2024-19  2305.79  33678.0  1351.76  80.06   71.8160  81.2640\n",
       "588  2024-20  2520.76  36014.0  1365.93  77.72   70.4220  79.8220\n",
       "\n",
       "[589 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aae30de8-b868-4c1c-9082-ebf3a7f21363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜를 인덱스로 설정\n",
    "df.set_index('주차', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4efad0b-d928-43fe-8690-ae970e70eb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCFI</th>\n",
       "      <th>코로나확진자</th>\n",
       "      <th>환율</th>\n",
       "      <th>WTI유가</th>\n",
       "      <th>나프타유가</th>\n",
       "      <th>고유황중유가</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>주차</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-52</th>\n",
       "      <td>1759.57</td>\n",
       "      <td>27732700.0</td>\n",
       "      <td>1314.16</td>\n",
       "      <td>73.81</td>\n",
       "      <td>74.1325</td>\n",
       "      <td>69.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-52</th>\n",
       "      <td>1759.57</td>\n",
       "      <td>27732700.0</td>\n",
       "      <td>1314.16</td>\n",
       "      <td>73.69</td>\n",
       "      <td>74.1325</td>\n",
       "      <td>69.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-52</th>\n",
       "      <td>1759.57</td>\n",
       "      <td>27732700.0</td>\n",
       "      <td>1253.50</td>\n",
       "      <td>73.81</td>\n",
       "      <td>74.1325</td>\n",
       "      <td>69.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-52</th>\n",
       "      <td>1759.57</td>\n",
       "      <td>27732700.0</td>\n",
       "      <td>1253.50</td>\n",
       "      <td>73.69</td>\n",
       "      <td>74.1325</td>\n",
       "      <td>69.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-52</th>\n",
       "      <td>1759.57</td>\n",
       "      <td>263390.0</td>\n",
       "      <td>1314.16</td>\n",
       "      <td>73.81</td>\n",
       "      <td>74.1325</td>\n",
       "      <td>69.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-52</th>\n",
       "      <td>1759.57</td>\n",
       "      <td>263390.0</td>\n",
       "      <td>1314.16</td>\n",
       "      <td>73.69</td>\n",
       "      <td>74.1325</td>\n",
       "      <td>69.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-52</th>\n",
       "      <td>1759.57</td>\n",
       "      <td>263390.0</td>\n",
       "      <td>1253.50</td>\n",
       "      <td>73.81</td>\n",
       "      <td>74.1325</td>\n",
       "      <td>69.605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SCFI      코로나확진자       환율  WTI유가    나프타유가  고유황중유가\n",
       "주차                                                           \n",
       "2023-52  1759.57  27732700.0  1314.16  73.81  74.1325  69.605\n",
       "2023-52  1759.57  27732700.0  1314.16  73.69  74.1325  69.605\n",
       "2023-52  1759.57  27732700.0  1253.50  73.81  74.1325  69.605\n",
       "2023-52  1759.57  27732700.0  1253.50  73.69  74.1325  69.605\n",
       "2023-52  1759.57    263390.0  1314.16  73.81  74.1325  69.605\n",
       "2023-52  1759.57    263390.0  1314.16  73.69  74.1325  69.605\n",
       "2023-52  1759.57    263390.0  1253.50  73.81  74.1325  69.605"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[563:570]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b5e6bc-116c-43da-838f-276a30b6f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[563:570], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad621cc0-b871-46ce-b58d-d94f1f89af88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCFI</th>\n",
       "      <th>코로나확진자</th>\n",
       "      <th>환율</th>\n",
       "      <th>WTI유가</th>\n",
       "      <th>나프타유가</th>\n",
       "      <th>고유황중유가</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>주차</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-1</th>\n",
       "      <td>1148.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1056.49</td>\n",
       "      <td>93.56</td>\n",
       "      <td>106.6980</td>\n",
       "      <td>96.1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-2</th>\n",
       "      <td>1232.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1058.35</td>\n",
       "      <td>95.56</td>\n",
       "      <td>105.0360</td>\n",
       "      <td>97.7760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-3</th>\n",
       "      <td>1245.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1075.58</td>\n",
       "      <td>95.88</td>\n",
       "      <td>103.4800</td>\n",
       "      <td>97.2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-4</th>\n",
       "      <td>1227.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1095.19</td>\n",
       "      <td>97.77</td>\n",
       "      <td>106.6620</td>\n",
       "      <td>97.4920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-5</th>\n",
       "      <td>1219.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1096.00</td>\n",
       "      <td>95.72</td>\n",
       "      <td>108.1780</td>\n",
       "      <td>98.5660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-15</th>\n",
       "      <td>1757.04</td>\n",
       "      <td>39459.0</td>\n",
       "      <td>1374.30</td>\n",
       "      <td>83.14</td>\n",
       "      <td>74.9875</td>\n",
       "      <td>79.6475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-16</th>\n",
       "      <td>1769.54</td>\n",
       "      <td>31841.0</td>\n",
       "      <td>1376.43</td>\n",
       "      <td>83.85</td>\n",
       "      <td>74.3400</td>\n",
       "      <td>80.8120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-17</th>\n",
       "      <td>1940.63</td>\n",
       "      <td>34278.0</td>\n",
       "      <td>1354.63</td>\n",
       "      <td>78.11</td>\n",
       "      <td>75.0220</td>\n",
       "      <td>80.4920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-19</th>\n",
       "      <td>2305.79</td>\n",
       "      <td>33678.0</td>\n",
       "      <td>1351.76</td>\n",
       "      <td>80.06</td>\n",
       "      <td>71.8160</td>\n",
       "      <td>81.2640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-20</th>\n",
       "      <td>2520.76</td>\n",
       "      <td>36014.0</td>\n",
       "      <td>1365.93</td>\n",
       "      <td>77.72</td>\n",
       "      <td>70.4220</td>\n",
       "      <td>79.8220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            SCFI   코로나확진자       환율  WTI유가     나프타유가   고유황중유가\n",
       "주차                                                          \n",
       "2013-1   1148.08      0.0  1056.49  93.56  106.6980  96.1060\n",
       "2013-2   1232.35      0.0  1058.35  95.56  105.0360  97.7760\n",
       "2013-3   1245.84      0.0  1075.58  95.88  103.4800  97.2140\n",
       "2013-4   1227.84      0.0  1095.19  97.77  106.6620  97.4920\n",
       "2013-5   1219.39      0.0  1096.00  95.72  108.1780  98.5660\n",
       "...          ...      ...      ...    ...       ...      ...\n",
       "2024-15  1757.04  39459.0  1374.30  83.14   74.9875  79.6475\n",
       "2024-16  1769.54  31841.0  1376.43  83.85   74.3400  80.8120\n",
       "2024-17  1940.63  34278.0  1354.63  78.11   75.0220  80.4920\n",
       "2024-19  2305.79  33678.0  1351.76  80.06   71.8160  81.2640\n",
       "2024-20  2520.76  36014.0  1365.93  77.72   70.4220  79.8220\n",
       "\n",
       "[581 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce382654-6420-4a7b-8976-efd2b70541a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('환율', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ac55f20-946a-4316-a829-fa960b77cf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCFI</th>\n",
       "      <th>코로나확진자</th>\n",
       "      <th>WTI유가</th>\n",
       "      <th>나프타유가</th>\n",
       "      <th>고유황중유가</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>주차</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-1</th>\n",
       "      <td>1148.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.56</td>\n",
       "      <td>106.6980</td>\n",
       "      <td>96.1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-2</th>\n",
       "      <td>1232.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.56</td>\n",
       "      <td>105.0360</td>\n",
       "      <td>97.7760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-3</th>\n",
       "      <td>1245.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.88</td>\n",
       "      <td>103.4800</td>\n",
       "      <td>97.2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-4</th>\n",
       "      <td>1227.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.77</td>\n",
       "      <td>106.6620</td>\n",
       "      <td>97.4920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-5</th>\n",
       "      <td>1219.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.72</td>\n",
       "      <td>108.1780</td>\n",
       "      <td>98.5660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-15</th>\n",
       "      <td>1757.04</td>\n",
       "      <td>39459.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>74.9875</td>\n",
       "      <td>79.6475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-16</th>\n",
       "      <td>1769.54</td>\n",
       "      <td>31841.0</td>\n",
       "      <td>83.85</td>\n",
       "      <td>74.3400</td>\n",
       "      <td>80.8120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-17</th>\n",
       "      <td>1940.63</td>\n",
       "      <td>34278.0</td>\n",
       "      <td>78.11</td>\n",
       "      <td>75.0220</td>\n",
       "      <td>80.4920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-19</th>\n",
       "      <td>2305.79</td>\n",
       "      <td>33678.0</td>\n",
       "      <td>80.06</td>\n",
       "      <td>71.8160</td>\n",
       "      <td>81.2640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-20</th>\n",
       "      <td>2520.76</td>\n",
       "      <td>36014.0</td>\n",
       "      <td>77.72</td>\n",
       "      <td>70.4220</td>\n",
       "      <td>79.8220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            SCFI   코로나확진자  WTI유가     나프타유가   고유황중유가\n",
       "주차                                                 \n",
       "2013-1   1148.08      0.0  93.56  106.6980  96.1060\n",
       "2013-2   1232.35      0.0  95.56  105.0360  97.7760\n",
       "2013-3   1245.84      0.0  95.88  103.4800  97.2140\n",
       "2013-4   1227.84      0.0  97.77  106.6620  97.4920\n",
       "2013-5   1219.39      0.0  95.72  108.1780  98.5660\n",
       "...          ...      ...    ...       ...      ...\n",
       "2024-15  1757.04  39459.0  83.14   74.9875  79.6475\n",
       "2024-16  1769.54  31841.0  83.85   74.3400  80.8120\n",
       "2024-17  1940.63  34278.0  78.11   75.0220  80.4920\n",
       "2024-19  2305.79  33678.0  80.06   71.8160  81.2640\n",
       "2024-20  2520.76  36014.0  77.72   70.4220  79.8220\n",
       "\n",
       "[581 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a60237f6-c610-408a-b73e-02b07adf2db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['SCFI'],axis=1)\n",
    "Y = df['SCFI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "043e5bbe-8154-4ef6-a7c9-aca6adca3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화\n",
    "scaler_X = RobustScaler()\n",
    "scaled_X = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_Y = RobustScaler()\n",
    "scaled_Y = scaler_Y.fit_transform(Y.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bdce09b-02c6-4979-bf2f-d23d2f52cdfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "348/348 [==============================] - 15s 14ms/step - loss: 8.0945 - mae: 1.5720 - val_loss: 3.7874 - val_mae: 1.1149\n",
      "Epoch 2/100\n",
      "348/348 [==============================] - 3s 10ms/step - loss: 4.3095 - mae: 1.2539 - val_loss: 2.5613 - val_mae: 0.9029\n",
      "Epoch 3/100\n",
      "348/348 [==============================] - 3s 8ms/step - loss: 4.0313 - mae: 1.1867 - val_loss: 2.3730 - val_mae: 0.9188\n",
      "Epoch 4/100\n",
      "348/348 [==============================] - 3s 10ms/step - loss: 3.4685 - mae: 1.1198 - val_loss: 2.1723 - val_mae: 0.8980\n",
      "Epoch 5/100\n",
      "348/348 [==============================] - 3s 9ms/step - loss: 3.6845 - mae: 1.1321 - val_loss: 2.0639 - val_mae: 0.8301\n",
      "Epoch 6/100\n",
      "348/348 [==============================] - 3s 9ms/step - loss: 3.5948 - mae: 1.1388 - val_loss: 2.2329 - val_mae: 0.8602\n",
      "Epoch 7/100\n",
      "348/348 [==============================] - 3s 9ms/step - loss: 4.0337 - mae: 1.1773 - val_loss: 2.3383 - val_mae: 0.8900\n",
      "Epoch 8/100\n",
      "348/348 [==============================] - 3s 8ms/step - loss: 3.4369 - mae: 1.1079 - val_loss: 2.5432 - val_mae: 0.9171\n",
      "Epoch 9/100\n",
      "348/348 [==============================] - 3s 8ms/step - loss: 3.4911 - mae: 1.0901 - val_loss: 2.7769 - val_mae: 0.9476\n",
      "Epoch 10/100\n",
      "348/348 [==============================] - 3s 9ms/step - loss: 3.6183 - mae: 1.1126 - val_loss: 2.1638 - val_mae: 0.8703\n",
      "Epoch 11/100\n",
      "348/348 [==============================] - 3s 9ms/step - loss: 3.9349 - mae: 1.1534 - val_loss: 2.3491 - val_mae: 0.8835\n",
      "Epoch 12/100\n",
      "348/348 [==============================] - 4s 10ms/step - loss: 3.8005 - mae: 1.1332 - val_loss: 2.0935 - val_mae: 0.8469\n",
      "Epoch 13/100\n",
      "348/348 [==============================] - 3s 8ms/step - loss: 3.4823 - mae: 1.1153 - val_loss: 2.2382 - val_mae: 0.9154\n",
      "Epoch 14/100\n",
      "348/348 [==============================] - 3s 9ms/step - loss: 3.5322 - mae: 1.0816 - val_loss: 2.0557 - val_mae: 0.8484\n",
      "Epoch 15/100\n",
      "348/348 [==============================] - 3s 9ms/step - loss: 3.5251 - mae: 1.1070 - val_loss: 2.3053 - val_mae: 0.8797\n",
      "Epoch 16/100\n",
      "348/348 [==============================] - 4s 11ms/step - loss: 3.5991 - mae: 1.1331 - val_loss: 2.1424 - val_mae: 0.8548\n",
      "Epoch 17/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.2986 - mae: 1.0657 - val_loss: 2.0489 - val_mae: 0.8413\n",
      "Epoch 18/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.5772 - mae: 1.1175 - val_loss: 2.0988 - val_mae: 0.8311\n",
      "Epoch 19/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.7127 - mae: 1.1100 - val_loss: 2.2242 - val_mae: 0.8408\n",
      "Epoch 20/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.6085 - mae: 1.1104 - val_loss: 2.0654 - val_mae: 0.8401\n",
      "Epoch 21/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.1484 - mae: 1.0645 - val_loss: 2.1203 - val_mae: 0.8665\n",
      "Epoch 22/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.3350 - mae: 1.0780 - val_loss: 2.3564 - val_mae: 0.8830\n",
      "Epoch 23/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.7944 - mae: 1.1293 - val_loss: 2.2855 - val_mae: 0.8739\n",
      "Epoch 24/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.6494 - mae: 1.1317 - val_loss: 2.1526 - val_mae: 0.8752\n",
      "Epoch 25/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.5812 - mae: 1.1025 - val_loss: 2.0744 - val_mae: 0.8473\n",
      "Epoch 26/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.4015 - mae: 1.0825 - val_loss: 2.2470 - val_mae: 0.8575\n",
      "Epoch 27/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.3410 - mae: 1.0480 - val_loss: 2.0853 - val_mae: 0.8240\n",
      "Epoch 28/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.5112 - mae: 1.0710 - val_loss: 2.0507 - val_mae: 0.8189\n",
      "Epoch 29/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.4424 - mae: 1.0926 - val_loss: 2.0466 - val_mae: 0.8236\n",
      "Epoch 30/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.3515 - mae: 1.0520 - val_loss: 2.0997 - val_mae: 0.8430\n",
      "Epoch 31/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.5598 - mae: 1.1006 - val_loss: 2.3893 - val_mae: 0.8845\n",
      "Epoch 32/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.4026 - mae: 1.0723 - val_loss: 2.0253 - val_mae: 0.8211\n",
      "Epoch 33/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.4422 - mae: 1.0616 - val_loss: 2.0404 - val_mae: 0.8364\n",
      "Epoch 34/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.4815 - mae: 1.0773 - val_loss: 2.1146 - val_mae: 0.8738\n",
      "Epoch 35/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.5625 - mae: 1.0969 - val_loss: 2.1417 - val_mae: 0.8647\n",
      "Epoch 36/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.4685 - mae: 1.1208 - val_loss: 2.1778 - val_mae: 0.8523\n",
      "Epoch 37/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.6613 - mae: 1.1121 - val_loss: 2.1041 - val_mae: 0.8331\n",
      "Epoch 38/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.4692 - mae: 1.0888 - val_loss: 2.0943 - val_mae: 0.8362\n",
      "Epoch 39/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.4184 - mae: 1.0929 - val_loss: 2.1391 - val_mae: 0.8411\n",
      "Epoch 40/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.5018 - mae: 1.0890 - val_loss: 2.2325 - val_mae: 0.8718\n",
      "Epoch 41/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.5934 - mae: 1.0975 - val_loss: 2.0675 - val_mae: 0.8322\n",
      "Epoch 42/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.3994 - mae: 1.0786 - val_loss: 2.1343 - val_mae: 0.8524\n",
      "Epoch 43/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.3855 - mae: 1.1031 - val_loss: 2.0150 - val_mae: 0.8224\n",
      "Epoch 44/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.5442 - mae: 1.1055 - val_loss: 2.0402 - val_mae: 0.8420\n",
      "Epoch 45/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.4312 - mae: 1.0808 - val_loss: 2.0107 - val_mae: 0.8285\n",
      "Epoch 46/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.2239 - mae: 1.0773 - val_loss: 2.2240 - val_mae: 0.8549\n",
      "Epoch 47/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.6109 - mae: 1.0790 - val_loss: 2.0386 - val_mae: 0.8404\n",
      "Epoch 48/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.6169 - mae: 1.1023 - val_loss: 2.1050 - val_mae: 0.8365\n",
      "Epoch 49/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.6381 - mae: 1.1059 - val_loss: 2.0266 - val_mae: 0.8371\n",
      "Epoch 50/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.4905 - mae: 1.0756 - val_loss: 2.1106 - val_mae: 0.8483\n",
      "Epoch 51/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.4122 - mae: 1.1010 - val_loss: 2.0519 - val_mae: 0.8395\n",
      "Epoch 52/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.3518 - mae: 1.0779 - val_loss: 1.9986 - val_mae: 0.8242\n",
      "Epoch 53/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.5233 - mae: 1.0990 - val_loss: 2.0445 - val_mae: 0.8324\n",
      "Epoch 54/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.4412 - mae: 1.0815 - val_loss: 2.0654 - val_mae: 0.8330\n",
      "Epoch 55/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.4969 - mae: 1.0989 - val_loss: 2.0709 - val_mae: 0.8398\n",
      "Epoch 56/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.5062 - mae: 1.1033 - val_loss: 2.0368 - val_mae: 0.8370\n",
      "Epoch 57/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.5392 - mae: 1.1113 - val_loss: 2.2218 - val_mae: 0.8631\n",
      "Epoch 58/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.4398 - mae: 1.0843 - val_loss: 2.0370 - val_mae: 0.8298\n",
      "Epoch 59/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.4958 - mae: 1.0738 - val_loss: 2.0966 - val_mae: 0.8454\n",
      "Epoch 60/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.2248 - mae: 1.0487 - val_loss: 2.0714 - val_mae: 0.8380\n",
      "Epoch 61/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.6255 - mae: 1.1225 - val_loss: 2.1125 - val_mae: 0.8458\n",
      "Epoch 62/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.2941 - mae: 1.0793 - val_loss: 2.5581 - val_mae: 0.9075\n",
      "Epoch 63/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.3871 - mae: 1.0857 - val_loss: 2.3229 - val_mae: 0.8700\n",
      "Epoch 64/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.4347 - mae: 1.1051 - val_loss: 2.0895 - val_mae: 0.8395\n",
      "Epoch 65/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.4278 - mae: 1.0619 - val_loss: 2.0279 - val_mae: 0.8259\n",
      "Epoch 66/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.3894 - mae: 1.0672 - val_loss: 2.0896 - val_mae: 0.8491\n",
      "Epoch 67/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.5775 - mae: 1.0888 - val_loss: 2.1053 - val_mae: 0.8527\n",
      "Epoch 68/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.5603 - mae: 1.1144 - val_loss: 2.0241 - val_mae: 0.8382\n",
      "Epoch 69/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.4586 - mae: 1.0574 - val_loss: 2.1485 - val_mae: 0.8519\n",
      "Epoch 70/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.6715 - mae: 1.1306 - val_loss: 2.2561 - val_mae: 0.8875\n",
      "Epoch 71/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.3700 - mae: 1.0859 - val_loss: 2.0664 - val_mae: 0.8282\n",
      "Epoch 72/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.5482 - mae: 1.0746 - val_loss: 2.0048 - val_mae: 0.8401\n",
      "Epoch 73/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.6069 - mae: 1.1155 - val_loss: 2.0856 - val_mae: 0.8657\n",
      "Epoch 74/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.2358 - mae: 1.0802 - val_loss: 2.1976 - val_mae: 0.8622\n",
      "Epoch 75/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.3770 - mae: 1.0830 - val_loss: 2.1483 - val_mae: 0.8381\n",
      "Epoch 76/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.5820 - mae: 1.0776 - val_loss: 2.0336 - val_mae: 0.8365\n",
      "Epoch 77/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.4562 - mae: 1.0944 - val_loss: 2.1390 - val_mae: 0.8395\n",
      "Epoch 78/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.5065 - mae: 1.0922 - val_loss: 2.0016 - val_mae: 0.8266\n",
      "Epoch 79/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.5324 - mae: 1.1011 - val_loss: 2.0813 - val_mae: 0.8428\n",
      "Epoch 80/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.2642 - mae: 1.0476 - val_loss: 1.9590 - val_mae: 0.8192\n",
      "Epoch 81/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.4323 - mae: 1.0882 - val_loss: 1.9886 - val_mae: 0.8373\n",
      "Epoch 82/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 3.4768 - mae: 1.0805 - val_loss: 2.0286 - val_mae: 0.8314\n",
      "Epoch 83/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.4342 - mae: 1.0883 - val_loss: 2.1294 - val_mae: 0.8482\n",
      "Epoch 84/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.2757 - mae: 1.0470 - val_loss: 2.1185 - val_mae: 0.8494\n",
      "Epoch 85/100\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 3.6256 - mae: 1.1205 - val_loss: 2.0284 - val_mae: 0.8321\n",
      "Epoch 86/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.4965 - mae: 1.1101 - val_loss: 1.9714 - val_mae: 0.8117\n",
      "Epoch 87/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.6371 - mae: 1.1087 - val_loss: 2.0046 - val_mae: 0.8265\n",
      "Epoch 88/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.3620 - mae: 1.0916 - val_loss: 2.0039 - val_mae: 0.8217\n",
      "Epoch 89/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.2870 - mae: 1.0538 - val_loss: 2.0775 - val_mae: 0.8249\n",
      "Epoch 90/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.4726 - mae: 1.0703 - val_loss: 2.0292 - val_mae: 0.8367\n",
      "Epoch 91/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.4314 - mae: 1.0942 - val_loss: 2.0095 - val_mae: 0.8197\n",
      "Epoch 92/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.3566 - mae: 1.0595 - val_loss: 1.9924 - val_mae: 0.8188\n",
      "Epoch 93/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.4338 - mae: 1.0900 - val_loss: 1.9643 - val_mae: 0.8161\n",
      "Epoch 94/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.4585 - mae: 1.0719 - val_loss: 1.9597 - val_mae: 0.8212\n",
      "Epoch 95/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.4385 - mae: 1.0739 - val_loss: 2.1305 - val_mae: 0.8641\n",
      "Epoch 96/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.3594 - mae: 1.0568 - val_loss: 2.0295 - val_mae: 0.8349\n",
      "Epoch 97/100\n",
      "348/348 [==============================] - 2s 5ms/step - loss: 3.5093 - mae: 1.1159 - val_loss: 2.0163 - val_mae: 0.8072\n",
      "Epoch 98/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.2547 - mae: 1.0412 - val_loss: 1.9621 - val_mae: 0.8174\n",
      "Epoch 99/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.2898 - mae: 1.0542 - val_loss: 2.2080 - val_mae: 0.8698\n",
      "Epoch 100/100\n",
      "348/348 [==============================] - 2s 6ms/step - loss: 3.2738 - mae: 1.0402 - val_loss: 2.2511 - val_mae: 0.8776\n",
      "4/4 [==============================] - 1s 7ms/step - loss: 2.3245 - mae: 0.9474\n",
      "Test loss: 2.325\n",
      "Test MAE: 0.947\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m test_predict \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# 예측 데이터 역정규화\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m train_predict \u001b[38;5;241m=\u001b[39m scaler_Y\u001b[38;5;241m.\u001b[39minverse_transform(train_predict)\n\u001b[0;32m     44\u001b[0m valid_predict \u001b[38;5;241m=\u001b[39m scaler_Y\u001b[38;5;241m.\u001b[39minverse_transform(valid_predict)\n\u001b[0;32m     45\u001b[0m test_predict \u001b[38;5;241m=\u001b[39m scaler_Y\u001b[38;5;241m.\u001b[39minverse_transform(test_predict)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1610\u001b[0m, in \u001b[0;36mRobustScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Scale back the data to the original representation.\u001b[39;00m\n\u001b[0;32m   1598\u001b[0m \n\u001b[0;32m   1599\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1607\u001b[0m \u001b[38;5;124;03m    Transformed array.\u001b[39;00m\n\u001b[0;32m   1608\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1609\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1610\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1611\u001b[0m     X,\n\u001b[0;32m   1612\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1613\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy,\n\u001b[0;32m   1614\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m   1615\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1616\u001b[0m )\n\u001b[0;32m   1618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_scaling:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m     )\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m     )\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    921\u001b[0m     _assert_all_finite(\n\u001b[0;32m    922\u001b[0m         array,\n\u001b[0;32m    923\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    924\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    925\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    926\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. None expected <= 2."
     ]
    }
   ],
   "source": [
    "# 데이터셋을 훈련, 검증 및 테스트 세트로 분할\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(scaled_X, scaled_Y, test_size=0.4, random_state=42)\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Transformer 입력 형태로 데이터 변환 [samples, time steps, features]\n",
    "x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_valid = x_valid.reshape((x_valid.shape[0], 1, x_valid.shape[1]))\n",
    "x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "# Transformer 모델 생성 함수\n",
    "def transformer_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    attention_output = MultiHeadAttention(num_heads=4, key_dim=input_shape[1])(x, x)\n",
    "    attention_output = Dropout(0.1)(attention_output)\n",
    "    attention_output = LayerNormalization(epsilon=1e-6)(attention_output + inputs)\n",
    "\n",
    "    x = Dense(128, activation='relu')(attention_output)\n",
    "    x = Dropout(0.1)(x)\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# 모델 생성\n",
    "model = transformer_model((1, x_train.shape[2]))\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=100, batch_size=1, verbose=1)\n",
    "\n",
    "# 모델 예측\n",
    "train_predict = model.predict(x_train)\n",
    "valid_predict = model.predict(x_valid)\n",
    "test_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19a78568-aa10-42d9-8b68-04c196c1b2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 2.3245 - mae: 0.9474\n",
      "Test loss:2.325\n",
      "Test MAE:0.947\n"
     ]
    }
   ],
   "source": [
    "loss, mae = model.evaluate(x_test,y_test)\n",
    "print(f'Test loss:{loss:.3f}')\n",
    "print(f'Test MAE:{mae:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "000c19cc-de45-49e2-afc9-fa86c54efe63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n",
      "R2 Score: 0.717\n"
     ]
    }
   ],
   "source": [
    "train_predict = scaler_Y.inverse_transform(train_predict.reshape(-1, 1))\n",
    "valid_predict = scaler_Y.inverse_transform(valid_predict.reshape(-1, 1))\n",
    "test_predict = scaler_Y.inverse_transform(test_predict.reshape(-1, 1))\n",
    "\n",
    "# 실제 데이터 역정규화\n",
    "y_train_actual = scaler_Y.inverse_transform(y_train.reshape(-1, 1))\n",
    "y_valid_actual = scaler_Y.inverse_transform(y_valid.reshape(-1, 1))\n",
    "y_test_actual = scaler_Y.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# R2 Score 계산\n",
    "y_hat = model.predict(x_test).reshape(-1, 1)\n",
    "y_hat = scaler_Y.inverse_transform(y_hat)\n",
    "r2 = r2_score(y_test_actual, y_hat)\n",
    "print(f'R2 Score: {r2:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
